{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load local model",
   "id": "622c0ec788a57a36"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-19T15:42:02.807268Z",
     "start_time": "2025-03-19T15:41:49.620804Z"
    }
   },
   "source": [
    "# Local\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from libs.core.tests.unit_tests.output_parsers.test_openai_tools import message\n",
    "\n",
    "ds_chat = ChatOllama(model=\"deepseek-r1:7b\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guosh\\AppData\\Local\\Temp\\ipykernel_69060\\862749496.py:6: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  ds_chat = ChatOllama(model=\"deepseek-r1:7b\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Maintain message list",
   "id": "8fa7941c88ae1661"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:52:24.464327Z",
     "start_time": "2025-03-19T15:52:10.887203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant. Answer all questions to the best of your ability. Answer in English.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | ds_chat\n",
    "mes_list=    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate from English to French: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    "ai_msg = chain.invoke(mes_list)\n",
    "print(ai_msg.content)"
   ],
   "id": "f8f7366b2cec39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user initially asked me to translate \"I love programming.\" into French. My response was straightforward with \"J'adore la programmation.\" Now, looking at the conversation history, after that translation, the user followed up by asking, \"What did you just say?\" \n",
      "\n",
      "Hmm, I think they're testing my ability or maybe curious about how I handled the request. They might be checking if I understood correctly when translating from English to French.\n",
      "\n",
      "I need to make sure my response is clear and helpful here. Maybe acknowledge that I translated it for them. Adding an emoji could make the response friendlier, which sometimes helps in building rapport with users.\n",
      "\n",
      "Also, offering further assistance shows that I'm ready to help more if they have another question or need something else. So putting it all together: a friendly acknowledgment followed by an offer to continue assisting.\n",
      "</think>\n",
      "\n",
      "Je viens de te r√©pondre que je t'adore ! C'est donc un cauchemar ? Je me demande si tu veux que je te dise quoi de plus !\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
